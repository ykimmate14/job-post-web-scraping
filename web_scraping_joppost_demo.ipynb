{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program asks a user to enter a **job title** and **location** of interest and scrapes relavant data from [a job posting website](www.indeed.com). Using NLTK, it removes stopwords and count the splited words. Then it asks a user to enter specific set of skills(separated by space) and return the sorted list of **skills** with number of occurence.\n",
    "\n",
    "The goal for the small program is to help users to find out which skills and talents are mostly desired by employees. \n",
    "\n",
    "For example, if you want to know if python is more demanded than R for 'data analyst' position, you can figure it out yourself as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests # for accesing web page\n",
    "from bs4 import BeautifulSoup # for pulling data out of html\n",
    "import pandas as pd # for general working with data\n",
    "# from nltk import word_tokenize # text mining / analysis\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import re #regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function take jobtitle and location as arguments and return correct url for web scraping purpose\n",
    "def searchquery(jobtitle, location):\n",
    "    title = jobtitle.replace(' ', '+')\n",
    "    loc = location.replace(' ', '+')\n",
    "    url = 'http://www.indeed.com/jobs?q=%22'+ title +'%22&radius=50&limit=50&l='+loc\n",
    "    return url\n",
    "\n",
    "# A function to take job list's url as an input and return dataframe with job titles and url to job post\n",
    "def collect_job_list(url):\n",
    "    # create empty list\n",
    "    jobtitle, hreflink = [], []\n",
    "    \n",
    "    # get contents from the web\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    # find the page number\n",
    "    x = soup.findAll('div', {'id': 'searchCount'})[0].text.replace(',', '')\n",
    "    pageN = int(x[x.find('of ')+3:])\n",
    "    \n",
    "    # iterate over page number    \n",
    "    for i in range(0, pageN, 50):\n",
    "        joblisturl = url + '&start=' + str(i)\n",
    "        r = requests.get(joblisturl)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        \n",
    "        # iterate over each listed job post on search result to obtain job title and link\n",
    "        for data in soup.findAll('a', {'data-tn-element': 'jobTitle'}):\n",
    "            if 'clk?jk=' in data.get('href'):\n",
    "                hreflink.append(data.get('href'))\n",
    "                jobtitle.append(data.text)\n",
    "    df = pd.DataFrame({'title': jobtitle, 'link': hreflink})\n",
    "    return df\n",
    "\n",
    "\n",
    "# convert the href link data in dataframe to proper url\n",
    "def properurl(link):\n",
    "    joburl = 'http://www.indeed.com/viewjob?jk=' +\\\n",
    "            link[link.find('clk?jk=')+len('clk?jk='):link.find('&fccid')]\n",
    "    return joburl\n",
    "            \n",
    "\n",
    "# A function to take job posting's url as an input, mine text data from selected job post. \n",
    "# and return the text from the post.\n",
    "def collect_job_data(joblink_list):\n",
    "    jobdesc = []\n",
    "    #iterate over href link in data frame\n",
    "    for i in range(0, len(joblink_list)):\n",
    "        joburl = properurl(joblink_list[i])\n",
    "        \n",
    "        #extracting text data from selected job posting        \n",
    "        r = requests.get(joburl)\n",
    "        soup = BeautifulSoup(r.content, 'html.parser')\n",
    "        desc = ''.join(soup.findAll('td', {'class': 'snip'})[0].text)\n",
    "        desc = re.sub('[^A-Za-z0-9&]+', ' ', desc)\n",
    "        jobdesc.append(desc[:desc.find('ago')].replace('\\n', ' ').lower())\n",
    "    return jobdesc\n",
    "\n",
    "# A function to take str as input, split the str and count the words\n",
    "def countword(text):\n",
    "    #removing stopwords from the data\n",
    "    stop = stopwords.words('english')   \n",
    "    \n",
    "    nostopword = ' '.join([word for word in text.split() if word not in stop])\n",
    "    #create word count list\n",
    "    count = Counter(nostopword.split())\n",
    "    return count\n",
    "\n",
    "# A function to take words as input and return the list of counts for the words of interest.\n",
    "def sortlist(words, countlist):\n",
    "    result= []  \n",
    "    for word in words.split():\n",
    "        result.append([x for x in countlist if word in x])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the \"job title\" of interest:  data analyst\n",
      "Please enter the \"location\" of interest:  california\n",
      "Number of open position: 528\n",
      "\n",
      "The 100 most frequent words are as below:\n",
      "\n",
      "[('data', 4658), ('experience', 1964), ('business', 1565), ('skills', 1060), ('work', 1051), ('analysis', 938), ('team', 938), ('ability', 849), ('analyst', 819), ('management', 665), ('support', 608), ('strong', 589), ('years', 578), ('knowledge', 546), ('sql', 539), ('analytics', 538), ('reporting', 537), ('required', 508), ('requirements', 489), ('tools', 488), ('information', 487), ('days', 474), ('working', 471), ('development', 457), ('product', 449), ('reports', 446), ('quality', 411), ('including', 411), ('systems', 392), ('technical', 389), ('develop', 389), ('related', 388), ('position', 385), ('job', 379), ('environment', 370), ('customer', 362), ('degree', 361), ('using', 349), ('preferred', 348), ('company', 346), ('provide', 343), ('&', 342), ('analytical', 340), ('insights', 336), ('communication', 333), ('marketing', 329), ('new', 329), ('projects', 317), ('responsibilities', 311), ('understanding', 309), ('must', 308), ('teams', 307), ('time', 305), ('design', 300), ('solutions', 300), ('excel', 298), ('project', 298), ('process', 295), ('health', 287), ('services', 279), ('role', 276), ('key', 273), ('processes', 272), ('research', 270), ('3', 261), ('education', 259), ('complex', 259), ('statistical', 259), ('perform', 258), ('analyze', 256), ('help', 255), ('create', 252), ('science', 248), ('identify', 248), ('manage', 246), ('software', 245), ('based', 243), ('qualifications', 243), ('performance', 241), ('plus', 241), ('2', 240), ('organization', 240), ('within', 239), ('client', 239), ('30', 235), ('large', 232), ('opportunity', 232), ('results', 228), ('high', 226), ('system', 226), ('across', 226), ('looking', 225), ('various', 225), ('computer', 224), ('well', 223), ('etc', 222), ('excellent', 220), ('financial', 218), ('database', 218), ('5', 217)]\n"
     ]
    }
   ],
   "source": [
    "# prompt a user to input job title and location of interest\n",
    "jobtitle = input('Please enter the \"job title\" of interest:  ') \n",
    "location = input('Please enter the \"location\" of interest:  ')\n",
    "\n",
    "# using the 'collect_job_list' funciton, assign data frame to a variable 'df' \n",
    "df = collect_job_list(searchquery(jobtitle, location))\n",
    "\n",
    "# remove duplicated data\n",
    "df = df[df.duplicated('link') == False]\n",
    "\n",
    "# add column of text that contains job description to the dataframe\n",
    "df['text'] = collect_job_data(list(df.link))\n",
    "\n",
    "# Clean data with text whose length is less than 100\n",
    "for index, row in df.iterrows():\n",
    "    if(len(row.text) < 100):\n",
    "        row.text = ''\n",
    "df = df[df.text != '']\n",
    "\n",
    "# iterate over the dataframe to split the texts into words\n",
    "for index, row in df.iterrows():\n",
    "    row.text = countword(row.text)\n",
    "\n",
    "# count the occurence of words\n",
    "totalcount = Counter()\n",
    "for index, row in df.iterrows():\n",
    "    totalcount += row.text\n",
    "\n",
    "# reorder the list of count in descending order\n",
    "result = totalcount.most_common()\n",
    "\n",
    "# overview of the most frequent words\n",
    "print(\"Number of open position: \"+str(len(df)))\n",
    "print(\"\\nThe 100 most frequent words are as below:\\n\")\n",
    "print(result[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the words of interst separated by space\n",
      "sql excel r python hadoop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('sql', 539)],\n",
       " [('excel', 298)],\n",
       " [('r', 108)],\n",
       " [('python', 111)],\n",
       " [('hadoop', 62)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt a user to sort the list with words of interest\n",
    "intwords = input('Enter the words of interst separated by space\\n')\n",
    "sortlist(intwords, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The most desired skill for 'data analyst' is SQL, followed by excel, which is ubiquitous tool for any industry.\n",
    "\n",
    "R and Python are almost equivalently demanded by employers.\n",
    "\n",
    "Hadoop is less demanded than other skills for 'data analyst' position."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
